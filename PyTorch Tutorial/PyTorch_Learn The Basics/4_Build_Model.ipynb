{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망 모델 구성하기\n",
    "- FashionMNIST 데이터셋의 이미지들을 분류하는 신경망 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn     # 신경망을 구성하는데 필요한 모든 구성 요소들 제공\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습을 위한 장치 얻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 클래스 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([5])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device = device)\n",
    "logits = model(X)                           # model.forward() : (x) / logits.size() = (1, 10)\n",
    "pred_probab = nn.Softmax(dim = 1)(logits)   # [0, 1]로 scaling (sum to 1)\n",
    "y_pred = pred_probab.argmax(dim = 1)\n",
    "print(f'Predicted class: {y_pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 계층(Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3, 28, 28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. nn.Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features = 28 * 28, out_features = 20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. nn.ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[-0.7028,  0.1240, -0.1343, -0.3060,  0.0752,  0.2318,  0.4740, -0.1087,\n",
      "         -0.0405,  0.0374,  0.5884,  0.0795,  0.2573,  0.1576, -0.2356,  0.1981,\n",
      "         -0.0522,  0.0670,  0.5634, -0.1215],\n",
      "        [-0.7102,  0.1744,  0.1251, -0.0910, -0.3544,  0.2280,  0.5323,  0.1253,\n",
      "         -0.3093,  0.0626,  0.4260,  0.1255,  0.6618,  0.3385,  0.0418,  0.1407,\n",
      "         -0.1403,  0.0120,  0.4167, -0.1188],\n",
      "        [-0.8503,  0.1020,  0.2596, -0.2336, -0.1066,  0.1367,  0.7367, -0.1176,\n",
      "         -0.4444,  0.0555,  0.1399,  0.3513,  0.3577,  0.1693,  0.0856,  0.5790,\n",
      "         -0.2805,  0.1058,  0.3868, -0.1471]], grad_fn=<AddmmBackward>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.0000, 0.1240, 0.0000, 0.0000, 0.0752, 0.2318, 0.4740, 0.0000, 0.0000,\n",
      "         0.0374, 0.5884, 0.0795, 0.2573, 0.1576, 0.0000, 0.1981, 0.0000, 0.0670,\n",
      "         0.5634, 0.0000],\n",
      "        [0.0000, 0.1744, 0.1251, 0.0000, 0.0000, 0.2280, 0.5323, 0.1253, 0.0000,\n",
      "         0.0626, 0.4260, 0.1255, 0.6618, 0.3385, 0.0418, 0.1407, 0.0000, 0.0120,\n",
      "         0.4167, 0.0000],\n",
      "        [0.0000, 0.1020, 0.2596, 0.0000, 0.0000, 0.1367, 0.7367, 0.0000, 0.0000,\n",
      "         0.0555, 0.1399, 0.3513, 0.3577, 0.1693, 0.0856, 0.5790, 0.0000, 0.1058,\n",
      "         0.3868, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0857,  0.0795, -0.2202,  0.1652,  0.0990, -0.1084, -0.1047,  0.1225,\n",
      "          0.0221,  0.1386],\n",
      "        [-0.0704, -0.0062, -0.4138,  0.0372,  0.1390, -0.0691, -0.0496,  0.0769,\n",
      "          0.0735, -0.0647],\n",
      "        [-0.0103, -0.0388, -0.3705,  0.0347,  0.0376,  0.0040, -0.0058,  0.0383,\n",
      "         -0.0006,  0.0703]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "logits = seq_modules(input_image)    # logits.size() : torch.Size([3, 10])\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. nn.Softmax\n",
    "- 각 class에 대한 예측 확률을 나타내도록 [0, 1] 범위로 scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0901, 0.1063, 0.0788, 0.1158, 0.1084, 0.0881, 0.0884, 0.1110, 0.1004,\n",
      "         0.1128],\n",
      "        [0.0956, 0.1019, 0.0678, 0.1064, 0.1178, 0.0957, 0.0976, 0.1107, 0.1104,\n",
      "         0.0961],\n",
      "        [0.1007, 0.0979, 0.0703, 0.1054, 0.1057, 0.1022, 0.1012, 0.1058, 0.1017,\n",
      "         0.1092]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)    # dim : 값의 합이 1이 되는 차원\n",
    "pred_probab = softmax(logits)\n",
    "print(pred_probab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 매개변수\n",
    "- 모델의 ```parameters()``` or ```named_parameters()```를 이용해 모든 매개변수에 접근 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values: tensor([[-0.0266,  0.0242,  0.0219,  ..., -0.0148, -0.0325,  0.0253],\n",
      "        [-0.0011,  0.0199, -0.0341,  ...,  0.0187, -0.0049, -0.0345]],\n",
      "       grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values: tensor([0.0347, 0.0192], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values: tensor([[-0.0104, -0.0387, -0.0014,  ...,  0.0370, -0.0243,  0.0066],\n",
      "        [-0.0294, -0.0404, -0.0268,  ..., -0.0131,  0.0348,  0.0283]],\n",
      "       grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values: tensor([-0.0172, -0.0160], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values: tensor([[ 0.0267, -0.0048,  0.0086,  ..., -0.0339,  0.0128,  0.0087],\n",
      "        [-0.0049,  0.0317,  0.0021,  ...,  0.0433,  0.0107, -0.0093]],\n",
      "       grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values: tensor([-0.0349,  0.0415], grad_fn=<SliceBackward>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Structure: \", model, \"\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values: {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dc1b947dce198ff7f2d2cb152b2cbb61132fce4429fa808fd5b89ac4d7df39fa"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
